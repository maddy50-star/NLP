{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qBARQxqgcT8d"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\n",
        "    \"Natural Language Processing is fun\",\n",
        "    \"I love learning Natural Language Processing\",\n",
        "    \"Text data is very important in NLP\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "0J50E-D6cvNc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_corpus = [text.lower() for text in corpus]\n",
        "print(processed_corpus)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mskH6T21c1Zh",
        "outputId": "73b7083f-9970-4de9-f771-9f8532693c77"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['natural language processing is fun', 'i love learning natural language processing', 'text data is very important in nlp']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bow_vectorizer = CountVectorizer()\n",
        "bow_matrix = bow_vectorizer.fit_transform(processed_corpus)\n"
      ],
      "metadata": {
        "id": "W_yUL_Rtc4hV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"BoW Feature Names:\")\n",
        "print(bow_vectorizer.get_feature_names_out())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nx_3qXmvdHmu",
        "outputId": "fa045660-291c-4dbc-847e-f37694230cf2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BoW Feature Names:\n",
            "['data' 'fun' 'important' 'in' 'is' 'language' 'learning' 'love' 'natural'\n",
            " 'nlp' 'processing' 'text' 'very']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"BoW Feature Matrix:\")\n",
        "print(bow_matrix.toarray())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_umJ1TqdTsB",
        "outputId": "239610e7-2269-4bb1-a10b-3bb396895c27"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BoW Feature Matrix:\n",
            "[[0 1 0 0 1 1 0 0 1 0 1 0 0]\n",
            " [0 0 0 0 0 1 1 1 1 0 1 0 0]\n",
            " [1 0 1 1 1 0 0 0 0 1 0 1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"BoW counts show frequency of words\")\n",
        "print(\"TF-IDF values show importance of words across documents\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JM5VBCl2doVW",
        "outputId": "170670f4-aaf6-402e-c998-c34208c66d02"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BoW counts show frequency of words\n",
            "TF-IDF values show importance of words across documents\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Define and fit the TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(processed_corpus)\n",
        "\n",
        "# Create DataFrames\n",
        "bow_df = pd.DataFrame(\n",
        "    bow_matrix.toarray(),\n",
        "    columns=bow_vectorizer.get_feature_names_out()\n",
        ")\n",
        "\n",
        "tfidf_df = pd.DataFrame(\n",
        "    tfidf_matrix.toarray(),\n",
        "    columns=tfidf_vectorizer.get_feature_names_out()\n",
        ")\n",
        "\n",
        "# Save to CSV\n",
        "bow_df.to_csv(\"bow_vectors.csv\", index=False)\n",
        "tfidf_df.to_csv(\"tfidf_vectors.csv\", index=False)"
      ],
      "metadata": {
        "id": "axroHY5Pdrw5"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}