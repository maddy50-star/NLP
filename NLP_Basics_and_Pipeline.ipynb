{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50e41a3f-5a9c-43f9-96e1-94bbf963fe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP Basics and NLP Pipeline\n",
    "\n",
    "#Natural Language Processing (NLP) enables computers to understand and process\n",
    "#human language using various text processing techniques.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25356015-58b0-4079-8dce-d76061cdabdc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNLTK imported successfully\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "print(\"NLTK imported successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba85a2ba-eeed-4678-9ece-dd8cf1581035",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tamil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tamil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\tamil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\tamil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\tamil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\tamil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0ad242-8879-420a-8782-9a9d15e18177",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NLP Basics\n",
    "\n",
    "Basic NLP operations include:\n",
    "- Sentence Segmentation\n",
    "- Tokenization\n",
    "- Stopword Removal\n",
    "- Stemming\n",
    "- Lemmatization\n",
    "- POS Tagging\n",
    "- Parsed Text\n",
    "- Named Entity Recognition (NER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69189e94-5412-4b3a-95be-95aa478f0864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      "Natural Language Processing is used in chatbots, search engines, and text analysis applications.\n"
     ]
    }
   ],
   "source": [
    "text = \"Natural Language Processing is used in chatbots, search engines, and text analysis applications.\"\n",
    "print(\"Original Text:\")\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8c2753-7250-4303-99ed-d618e23efd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Segmentation:\n",
      "['Natural Language Processing is used in chatbots, search engines, and text analysis applications.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sentences = sent_tokenize(text)\n",
    "print(\"Sentence Segmentation:\")\n",
    "print(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aaece6-96ec-4267-a24d-5c0c561d798e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens:\n",
      "['Natural', 'Language', 'Processing', 'is', 'used', 'in', 'chatbots', ',', 'search', 'engines', ',', 'and', 'text', 'analysis', 'applications', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokens = word_tokenize(text)\n",
    "print(\"Tokens:\")\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3853e7a-b77e-4490-903b-ba35474c9b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Stopword Removal:\n",
      "['Natural', 'Language', 'Processing', 'used', 'chatbots', ',', 'search', 'engines', ',', 'text', 'analysis', 'applications', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "\n",
    "print(\"After Stopword Removal:\")\n",
    "print(filtered_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cd882c-207e-4721-84a3-fcaaf9d2fe9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Stemming:\n",
      "['natur', 'languag', 'process', 'use', 'chatbot', ',', 'search', 'engin', ',', 'text', 'analysi', 'applic', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "stemmed_tokens = [ps.stem(word) for word in filtered_tokens]\n",
    "\n",
    "print(\"After Stemming:\")\n",
    "print(stemmed_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e79cb01-0291-46ec-9bbf-30b249fbdcd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Lemmatization:\n",
      "['Natural', 'Language', 'Processing', 'used', 'chatbots', ',', 'search', 'engine', ',', 'text', 'analysis', 'application', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "\n",
    "print(\"After Lemmatization:\")\n",
    "print(lemmatized_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bba006-efd7-4e3e-95f8-2f9823753571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags:\n",
      "[('Natural', 'JJ'), ('Language', 'NNP'), ('Processing', 'NNP'), ('is', 'VBZ'), ('used', 'VBN'), ('in', 'IN'), ('chatbots', 'NNS'), (',', ','), ('search', 'NN'), ('engines', 'NNS'), (',', ','), ('and', 'CC'), ('text', 'JJ'), ('analysis', 'NN'), ('applications', 'NNS'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "pos_tags = nltk.pos_tag(tokens)\n",
    "print(\"POS Tags:\")\n",
    "print(pos_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e5b74d-bcbd-424d-93e9-f0e6b9f06b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed Text:\n",
      "Natural -> JJ\n",
      "Language -> NNP\n",
      "Processing -> NNP\n",
      "is -> VBZ\n",
      "used -> VBN\n",
      "in -> IN\n",
      "chatbots -> NNS\n",
      ", -> ,\n",
      "search -> NN\n",
      "engines -> NNS\n",
      ", -> ,\n",
      "and -> CC\n",
      "text -> JJ\n",
      "analysis -> NN\n",
      "applications -> NNS\n",
      ". -> .\n"
     ]
    }
   ],
   "source": [
    "print(\"Parsed Text:\")\n",
    "for word, tag in pos_tags:\n",
    "    print(f\"{word} -> {tag}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f287ddef-a908-4ea9-ae45-46adb66652e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named Entity Recognition Tree:\n",
      "(S\n",
      "  Natural/JJ\n",
      "  Language/NNP\n",
      "  Processing/NNP\n",
      "  is/VBZ\n",
      "  used/VBN\n",
      "  in/IN\n",
      "  chatbots/NNS\n",
      "  ,/,\n",
      "  search/NN\n",
      "  engines/NNS\n",
      "  ,/,\n",
      "  and/CC\n",
      "  text/JJ\n",
      "  analysis/NN\n",
      "  applications/NNS\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "from nltk import ne_chunk\n",
    "\n",
    "ner_tree = ne_chunk(pos_tags)\n",
    "print(\"Named Entity Recognition Tree:\")\n",
    "print(ner_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfb6960-1a69-4947-bd3a-65a53387abef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NLP Pipeline Summary\n",
    "\n",
    "1. Text Input  \n",
    "2. Sentence Segmentation  \n",
    "3. Tokenization  \n",
    "4. Stopword Removal  \n",
    "5. Stemming  \n",
    "6. Lemmatization  \n",
    "7. POS Tagging  \n",
    "8. Parsed Text  \n",
    "9. Named Entity Recognition  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21150b48-1341-4f02-b345-9bb7e4d6d343",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates NLP basics and a complete NLP pipeline using NLTK,\n",
    "including segmentation, parsing, and named entity recognition.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spyder-runtime",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
